sudo apt update && sudo apt -y full-upgrade
[ -f /var/run/reboot-required ] && sudo reboot -f

For default system Java:
sudo apt install curl mlocate default-jdk -y
java -version

wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz

tar xvf spark-3.2.1-bin-hadoop3.2.tgz

sudo mv spark-3.2.1-bin-hadoop3.2/ /opt/spark 
nano ~/.bashrc

Add:
export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
source ~/.bashrc
Start a standalone master server
start-master.sh 
The process will be listening on TCP port 8080.
sudo ss -tunelp | grep 8080
start-slave.sh spark://ubuntu:7077
If you donâ€™t have the script in your $PATH, you can first locate it.

$ sudo updatedb
$ locate start-slave.sh
/opt/spark/sbin/start-slave.sh
Using Spark shell
/opt/spark/bin/spark-shell -> Scala
/opt/spark/bin/pyspark
Easily shut down the master and slave Spark processes using commands below.

$ SPARK_HOME/sbin/stop-slave.sh
$ SPARK_HOME/sbin/stop-master.sh
